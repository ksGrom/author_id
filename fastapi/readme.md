## Определение авторства текста

Микросервис на FastAPI для обучения и применения моделей для классификации текстов по авторству.

## FastAPI 

API микросервиса реализовано в `main.py` (25 методов). 

### Инструкция
*Подробная информация о формате входных и выходных данных API 
приведена в документации в формате OpenAPI (доступна по URL `/docs`)*.

1. Сформировать тренировочный и тестовый наборы данных.
   - Подготовить тренировочный и тестовый наборы текстов с
известным авторством в виде txt-файлов (кодировка UTF-8). 
Желательно, чтобы в тренировочном датасете каждый текст был цельным: если в датасете 
в виде нескольких текстов представлены отрывки, например, из одного романа,
то модель может переообучиться на признаки, характерные именно для романа
(напр., на имена персонажей). Кроме того, в тестовый датасет не должны 
включаться отрывки из текстов, отрывки из которых включены в тренировочный
датасет, во избежание завышенной оценки качества модели.
   - Для каждого автора из трен. набора сформировать один csv-файл 
с помощью метода `POST /merge_txt` (на вход: имя выходного файла; метка автора (латиницей, напр., *leo-tolstoy*),
которое будет указано в столбце *authors* в выходном файле; набор объединяемых 
текстовых файлов). Повторить для тестового набора.
   - Объединить полученные для трен. набора csv-файлы в один csv-файл 
с помощью метода `POST /merge_csv`. Повторить для тест. набора.
   - Если необходимо, воспользоваться методом `POST /cut_texts` для удаления
из начала и конца каждого текста определенного количества слов. Это может быть полезно,
если в текстах присутствует лишняя информация (напр., предисловие, информация об издании и т.п.).
На вход — csv-файл.
   - Если необходимо, убрать из полученных наборов короткие тексты 
с помощью метода `POST /remove_short_texts`. Может быть полезно, поскольку при 
обучении модели все тексты нарезаются на отрывки длиной приблизительно 250 слов;
наличие в трен. и тест. наборах более коротких текстов может привести к ухудшению
качества модели или занижению оценки качества. Применение модели на более коротких текстах
не рекомендуется. На вход: минимальная длина текста, csv-файл.

2. Добавить в приложение тренировочный датасет с помощью метода `POST /dataset`.
На вход: имя датасета; описание (опционально); файл, полученный в пункте 1. Повторить для
тестового датасета.
   - С помощью метода `PATCH /dataset/{dataset_id}` в датасет можно добавить
несколько текстов (в виде csv-файла).
   - С помощью метода `GET /dataset` можно получить список всех сохраненных датасетов, 
а также id датасета по его названию.
   - С помощью метода `GET /dataset/{dataset_id}` можно получить информацию об определенном датасете.
   - С помощью метода `PUT /dataset/{dataset_id}` можно отредактировать описание датасета.
   - Датасет можно удалить с помощью метода `DELETE /dataset/{dataset_id}`, если в приложении нет
ML-моделей, обученных или протестированных на данном датасете (в противном случае сначала необходимо
удалить ML-модель).
   - После загрузки датасета из него извлекаются метки авторов. Список сохраненных
авторов можно получить с помощью метода `GET /author`; список датасетов, в которых встречаются
тексты определенного автора, можно получить с помощью метода `GET /author/{author_id}`.

3. *(Необязательно)* С помощью метода `PATCH /author/{author_id}` обновить информацию об авторах (ФИО).

4. Запустить обучение модели на тренировочном датасете с помощью метода
`POST /train`. На вход: имя модели, описание модели (опционально), id датасета.
Будет запущен асинхронный процесс обучения модели (на csv файле размером в 65 Мбайт обучение 
длится до нескольких минут).
   - Информацию об обучении модели, в том числе текущем этапе обучения, можно получить с помощью
метода `GET /train/{training_id}`. Модель можно тестировать и применять, если ее статус 
указан как *"FINISHED"* (`"status": "FINISHED"`), в противном случае необходимо дождаться
завершения обучения модели.
   - С помощью метода `PATCH /train/{model_id}` можно дообучить (асинхронно) ранее обученную модель, если
связанный с ней тренировочный датасет обновился. 
   - С помощью метода `GET /train` можно получить список обучений всех моделей.
   - Подробную информацию о модели (в т.ч. информацию о связанных датасетах) можно получить 
с помощью метода `GET /model/{model_id}`.
   - С помощью метода `DELETE /model/{model_id}` модель можно удалить из приложения
(удаление из БД информации о модели, в т.ч. об обучении и тестировании, удаление файла модели).

5. Оценить качество модели на тестовом датасете с помощью метода `POST /test/{model_id}`.
Тестирование происходит асинхронно. На вход: id модели, id датасета.
   - Информацию о тестировании модели, в том числе текущем этапе тестирования, можно получить с помощью
метода `GET /test/{test_id}`. После завершения тестирования статус будет указан как *"FINISHED"* 
(`"status": "FINISHED"`).
   - С помощью метода `GET /test` можно получить список всех тестирований.

6. Теперь модель готова к применению. С помощью метода `PUT /predict/{model_id}`
можно получить предсказания модели на одном тексте (txt-файл) или наборе текстов (csv-файл).

## Установка 
*Ссылка на docker-образ: https://hub.docker.com/r/ksgrom/author_id*

Скачивание образа:
```bash
docker pull ksgrom/author_id
```

Пример создания и запуска в фоновом режиме контейнера из образа:
```bash
docker run --rm -d -p 8988:8000 --name author_id author_id
```
*Прим.* Если эта команда не работает, последнее `author_id` можно попробовать заменить на
`ksgrom/author_id`.

После выполнения этой команды с этого же ПК можно открыть в браузере
страницу с документацией в формате OpenAPI: `http://localhost:8988/docs` —
и протестировать приложение.

## Тестирование
Основные функции приложения реализованы в модулях `utils_dataset.py` и 
`utils_tfidf.py`, большая часть из них покрыта тестами; тесты находятся в папке tests.

Чтобы запустить тесты, достаточно дополнительным процессом открыть в контейнере терминал
и выполнить команду (из рабочей директории `/app`):
```bash
python3 -m pytest --cov . tests
```
