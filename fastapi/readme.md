## Определение авторства текста

Микросервис на FastAPI для обучения и применения моделей для классификации текстов по авторству.

## FastAPI 

API микросервиса реализовано в `main.py` (25 методов). Документация
в формате OpenAPI доступна по URL `/docs`.

### Инструкция
1. Сформировать тренировочный и тестовый наборы данных.
   - Подготовить тренировочный и тестовый набор текстов с
известным авторством в виде txt-файлов (кодировка UTF-8). 
Желательно, чтобы в тренировочном датасете каждый текст был цельным: если в датасете 
в виде нескольких текстов представлены отрывки, например, из одного романа,
то модель может переообучиться на признаки, характерные именно для романа
(напр., на имена персонажей). Кроме того, в тестовый датасет не должны 
включаться отрывки из текстов, отрывки из которых включены в тренировочный
датасет, во избежание завышенной оценки качества модели.
   - Для каждого автора из трен. набора сформировать один csv-файл 
с помощью метода `/merge_txt` (на вход: имя выходного файла; имя автора,
которое будет указано в столбце *authors* в выходном файле; набор объединяемых 
текстовых файлов). Повторить для тестового набора.
   - Объединить полученные для трен. набора csv-файлы в один csv-файл 
с помощью метода `/merge_csv`. Повторить для тест. набора.
   - Если необходимо, воспользоваться методом `/cut_texts` для удаления
из начала и конца каждого текста определенного количества слов. Это может быть полезно,
если в текстах присутствует лишняя информация (напр., предисловие, информация об издании и т.п.).
На вход — csv-файл.
   - Если необходимо, убрать из полученных наборов короткие тексты 
с помощью метода `/remove_short_texts`. Может быть полезно, поскольку при 
обучении модели все тексты нарезаются на отрывки длиной приблизительно 250 слов;
наличие в трен. и тест. наборах более коротких текстов может привести к ухудшению
качества модели или занижению оценки качества. Применение модели на более коротких текстах
не рекомендуется. На вход: минимальная длина текста, csv-файл.

2. 

Поддерживаются два расширения для входного файла: `.txt` и `.csv`. Входной файл
с расширением `txt` рассматривается программой как один текст. Если на вход подается
`csv`-таблица (набор текстов), то в ней должен быть столбец, озаглавленный как `text`.
Файл должен иметь кодировку UTF-8. Если файл невалидный, сервис ответит кодом 422 
(проверяются расширение, кодировка и, в случае csv-файла, наличие столбца `text`).
Документация в формате OpenAPI доступна по URL `/docs`.


## Установка 
*Ссылка на docker-образ: https://hub.docker.com/r/ksgrom/author_id*

Скачивание образа:
```bash
docker pull ksgrom/author_id
```

Пример создания и запуска в фоновом режиме контейнера из образа:
```bash
docker run --rm -d -p 8988:8000 --name author_id author_id
```

После выполнения этой команды с этого же ПК можно открыть в браузере
страницу с документацией в формате OpenAPI: `http://localhost:8988/docs` —
и протестировать приложение.

## Тестирование
Основные функции приложения реализованы в модулях `utils_dataset.py` и 
`utils_tfidf.py`, большая часть из них покрыта тестами; тесты находятся в папке tests.

Чтобы запустить тесты, достаточно дополнительным процессом открыть в контейнере терминал
и выполнить команду (из рабочей директории `/app`):
```bash
python3 -m pytest --cov . tests
```
